---

# ğŸ” Deep Dive: How Cassandra Stores Data Internally

## 1. **Keyspace Creation**

Example:

```sql
CREATE KEYSPACE prod_data
WITH REPLICATION = {
  'class': 'NetworkTopologyStrategy',
  'DC1': 3,
  'DC2': 2
};
```

* **Keyspace = database container.**
* Defines **replication factor (RF)** per datacenter.
* Cassandra does not store data in the keyspace directly â†’ keyspace contains **tables**.

---

## 2. **Table Creation**

```sql
CREATE TABLE prod_data.emp (
   emp_id int,
   emp_name text,
   salary int,
   PRIMARY KEY (emp_id)
);
```

* Table = **Column Family** in Cassandra.
* **Partition Key = emp\_id** decides data distribution.
* Each row identified by a **Partition Key â†’ Token** (using partitioner).

---

## 3. **Write Path (Arrow Flow)**

When you insert a row:

```sql
INSERT INTO prod_data.emp (emp_id, emp_name, salary)
VALUES (1, 'Sriram', 10000);
```

### Flow (internally):

```
Client Query
   â†“
Coordinator Node (receives request)
   â†“
Partitioner (Murmur3) â†’ Hash(emp_id=1) â†’ Token
   â†“
Replica Selection (based on RF=3 in DC1, RF=2 in DC2)
   â†“
Chosen Nodes (5 replicas total)
   â†“
On Each Replica:
   CommitLog (append-only, durable)
       â†“
   MemTable (in-memory structure per table)
       â†“ (flush when full or on schedule)
   SSTables (immutable disk files, stored on disk)
       â†“
   Compaction (merges multiple SSTables, clears tombstones)
```

---

## 4. **Read Path (Arrow Flow)**

When you run:

```sql
SELECT * FROM prod_data.emp WHERE emp_id=1;
```

### Flow:

```
Client Query
   â†“
Coordinator Node (based on token map)
   â†“
Consistency Check (LOCAL_QUORUM, QUORUM, etc.)
   â†“
Replicas Respond
   â†“
On Each Replica:
   Row Cache / Key Cache? (if hit â†’ fast return)
   â†“
   Bloom Filter (check if SSTable has key)
   â†“
   Partition Summary â†’ Partition Index â†’ Row Data
   â†“
   MemTable checked first (newest data)
   â†“
Coordinator merges results from replicas
   â†“
Client gets final response
```

---

## 5. **Compaction & Tombstone Cleanup**

* Multiple SSTables merged â†’ fewer files.
* Deleted rows (tombstones) permanently removed after `gc_grace_seconds`.

---

# ğŸ¯ Arrow-Based Diagram (Storage Flow)

Hereâ€™s a **visual text-based arrow diagram** of Cassandra write path:

```
[Client Write Request]
         â†“
 [Coordinator Node]
         â†“
 [Partitioner â†’ Token]
         â†“
 [Replica Selection (Snitch + RF)]
         â†“
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Replica Node (example DC1N2) â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
     [Commit Log]  â† durable log
         â†“
     [MemTable]    â† in-memory buffer
         â†“ (flush)
     [SSTable]     â† immutable disk file
         â†“
   [Compaction] â†’ merges SSTables, clears tombstones
```

And for the **read path**:

```
[Client Read Request]
         â†“
 [Coordinator Node]
         â†“
 [Consistency Level Check]
         â†“
 [Replicas Queried]
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Replica Node (search order): â”‚
  â”‚  1. Row/Key Cache            â”‚
  â”‚  2. MemTable                 â”‚
  â”‚  3. SSTable (via BloomFilter)â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
 [Coordinator Merges Results]
         â†“
 [Return to Client]
```

---

# âœ… Key Takeaways

* **Keyspace** defines replication policy, not actual storage.
* **Tables (Column Families)** store rows partitioned by key â†’ distributed across nodes.
* **Writes â†’ CommitLog + MemTable â†’ SSTables**.
* **Reads â†’ Cache â†’ MemTable â†’ SSTables (with Bloom filters & indexes)**.
* **Compaction** + **Tombstones** maintain efficiency over time.

---
